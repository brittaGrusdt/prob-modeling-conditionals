// var data = {
//     "verbose": [true],
//   "utt": ["E > S"],
//   "alpha": [5],
//   "prior_pe": [0.2]
// }

globalStore.thresholds = {theta: data["theta"][0], theta_likely : 0.5}
var vars = [["D", "-D"], ["S", "-S"], ["G", "-G"]]
var causal_nets = {"cn1": "D || G>-S", "cn2": "D>G>-S"}
var prior_cns = Categorical({"vs": ["cn1", "cn2"], "ps": [0.95, 0.05]})
var powerset = get_var_powerset(vars, false)
var utterances = make_utterances(powerset)

var verbose = data["verbose"][0]
var prior_pd = data["prior_pd"][0]
var utt = data["utt"][0]
var LEVEL_MAX = data["level_max"] ? data["level_max"][0] : "PL"
globalStore.alpha = data["alpha"][0]

if(verbose){
  display("alpha:" + globalStore.alpha)
  display('all utterances:' + utterances.length)
  display("prior P(D):" + prior_pd)
  display("listener hears utterance: " + utt)
}

// Probabilities ----------------------------------------------------------------
var probabilities = {"cn1": {"p_spading": {"G": 0, "-G": 0.5},
                             "p_passDriving": prior_pd,
                             "p_party": 0.5},
                     "cn2": {"p_spading": {"G": 0, "-G": 0.5},
                             "p_passDriving": prior_pd,
                             "p_party": {"D": 1, "-D": 0.5}}
                    }

// States ----------------------------------------------------------------
var joint_probs = function(token, cn){
  var probs = probabilities[cn]
  // passing driving test (D)
  var p_d = token.indexOf("-D") != -1 ? 1-probs["p_passDriving"] : probs["p_passDriving"]

  // garden party
  var gp = cn == "cn1" ? probs["p_party"] :
             token.indexOf("-D") != -1 ? probs["p_party"]["-D"] : probs["p_party"]["D"]
  var p_gp = token.indexOf("-G") != -1 ? 1-gp : gp

  // spading garden
  var s = token.indexOf("-G") != -1 ? probs["p_spading"]["-G"] : probs["p_spading"]["G"]
  var p_s = token.indexOf("-S") != -1 ? 1-s : s

  return p_s * p_gp * p_d
}
var var_combinations_len3 = filter(function(tokens){tokens.length==3}, powerset)
var var_combinations = {"cn1": var_combinations_len3, "cn2": var_combinations_len3}

var build_table_distr = cache(function(cn){
  var tokens_active = var_combinations[cn]
  var tokens_active_str = map(function(elems){elems.join("")}, tokens_active)
  return Infer({model:function(){
    var arr = map(function(elems){joint_probs(elems, cn)}, tokens_active_str)
    return categorical({vs:tokens_active_str, ps:arr})
  }})
})

var get_bn = function(cn){
  var Table = build_table_distr(cn)
  var bn = {"cn": causal_nets[cn], "table": Table}
  return bn
}

var state_prior = Infer({model:function(){
  var cn = sample(prior_cns)
  var bn = get_bn(cn)
  return bn
}})

globalStore.state_prior = state_prior

// // Utterances ----------------------------------------------------
var all_states = state_prior.support()
var utts_to_remove = filter(function(u){
  !any(function(s){meaning(u,s["table"])}, all_states)
}, utterances)
// map(display, utts_to_remove)
var utterances = filter(function(u){utts_to_remove.indexOf(u) == -1}, utterances)
globalStore.utterances = utterances
// map(display, utterances)
if(verbose){
  display('# utts without corresponding state: ' + utts_to_remove.length)
  display('# included utterances: ' + (globalStore.utterances).length)
}

// Run from R ----------------------------------------------------------------
var prior = state_prior
var ll = literal_listener(utt)
var pl = listener(utt)

// object to return
var distributions = {"PL": pl, "LL": ll, "prior": prior}
distributions
